---
layout: post
title: Orgs
date: 2024-12-12
summary: hmm
---

Main points:
- humans are "designed" to live and talk to other humans
- the highest possible level of service is having someone else attend specifically to your needs
- from a cybernetics perspective, organisations are essentially sentient
- organisations' brains were once entirely their people and organisational structure
    - physical and communicative boundaries limited these organisations' capabilities
- software has enabled us to offload an increasing share of the cognitive load of organisations to machines
    - paper -> spreadsheets -> applications -> etc.
- a property of traditional software is that designed abstractions are required.
    - These are necessarily simplifications of things in the world - people, products, materials, etc.
    - They reflect the organisations' understanding of the world
    - They have a practical ceiling to their complexity
- designed abstractions alienate. Institutions that use designed abstractions (traditional software) alienate and fail to serve their constituents.
- Recent advances in machine intelligence represent software that understands the world in a far richer way than traditional software.
    - this can be exemplified when comparing an latent space vector - a models encoding of its input data - to a 5-column relational database record and accompanying input form
    - a latent representation of an object an ML model has thousands of dimensions - GPT-2 Large had 1280 dimensions
    - a relational database table might have 5 columns. Let's say [name,  age, email_address, subscription, location] 
        - these are essentially the internal representation of your average software product.
        - they have been learned by software development best practices over the course of decades
        - they are simple, but effective. However, edge cases inevitably appear that this representation cannot address - for example, what if the user travels alot, and has no consistent location?
    - having technology that can automate learning of representations means we can let go of simple representations and instead embrace rich representations
- I have an optimistic accelerationist stance on this:
    - Traditional, designed software results in countless damaging effects on society, and is central to the feeling of inhumane dystopia
    - Advances in machine intelligence will mean organisations will be able to provide service approaching that of humans
    - Interacting with organisations will be more democratic in the future, and fewer people will fall outside of service.
    - we used to have human friendliness; then we had scale at the cost of human friendliness; soon we might be able to have both!
    - We are currently at peak digitalism; things will get more human-friendly from here!
    - imagine if a bank was just one person that understood the whole thing, and could talk to all of it's customers in person simultaneously
    - imagine if you could walk up to a water engineer and mention a leak you noticed in your neighbourhood, and suddenly another engineer is dispatched