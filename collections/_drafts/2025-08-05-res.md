---
layout: post
title: Res
date: 2024-12-12
summary: hmm
---

Ideas for biomimicry in NNs

- neuromorphic hardware sick, yet unproven, not accessible by consumers
- Feedforward NNs lacking some elements I think are core to intelligence
    - recurrence
    - event-drivenness(?)
    - plasticity
    - flexibility outside of api-style domains
    - speed
    - coherence
- current ML work relies on learning quite complex maths/stats
    - practitioner-based
    - "cool tricks" emerging from people trying new techniques, they become en-vogue
    - super complicated, innovation restricted more/less to people with PhDs working at foundation labs
    - creating the best models comes with obscene data gathering, cleaning pruning exercises that biological intelligence kinda didn't have to much encounter aside from billions of years of development and all that.
    - some tricks designed will have inductive biases/assumptions on how the brain works
    - vibes based, but I don't feel that intelligence will come down to some educated class finally "figuring out" how the brain works
        - it'll be something simple and lightweight, parallel, scaled pretty crazy, wherein intelligent behaviour emerges, rather than is trained in
- Reservoir computing has some ideas I really like
    - chaos as a core element of intelligence
    - randomised initial conditions
    - emergent behaviour
    - super light on compute
    - super simple
- There is something to the application of SGD in modern ML that doesn't quite feel right to me
    - although, models do seem to be able to generalise, right?
    - however, how are we going to fit an intelligence to a criteria that doesn't exist yet?
    - all of the above has been discussed at length, and yet still something feels off about our current approaches
    - Gradient descent/plasticity/optimisation I think will be a capability of future intelligences, but not the sum total of the system
        - learnings from current approaches will still be valid in new architectures and will make them crazy powerful. Like we've already done all this graft on the learning thing, once we figure out the other bit, it'll be supercharged
    - I have a hunch that, the fact that natural selection and SGD are different processes will come to be an important notion

Wild Speculation as to a paradigm that could be pretty capable in mimicking biological intelligence, and implementable on today's accessible hardware:
- reservoir computing principles
    - instantiate one or multiple hugely interconnected reservoirs of neurons
        - similar to regions of the brain, it may be that multiple reservoirs with autoencoder-style bottleneck layers to interconnect is a useful approach
            - reservoir for vision that ends up with convolutional style mechanisms
            - reservoir for audio
            - high-level task planning etc
            - motor control
    - signals from various sensors - visual, nervous, auditory, etc, etc provide input to reservoir
        - early iterations could use existing pretrained embeddings models to reduce features to reasonable dimensionality
    - Similar to LSMs, handle spiking in neurons.
        - incorporate a distance matrix alongside connections, which introduces a time-step based delay between a spike being sent and received by recipient neuron
    - build a repository of canonical neuron types
        - basic Leaky integrate + fire but also,
        - Thalamic relay neurons
        - Purkinje cells
        - not an exhaustive list, and would include a long tail of different types, but the idea is you have a repertoire of different flavours that could approximate most functions. These may be similar to but not the same as biological types. Kinda a digital port.
    - using some sort of "genetic seed" generate distributions of different types of neurons in the reservoir(s). reservoirs for certain tasks might have more of one type than another. Generate the weights, biases, leak rates, and distances between them based on this seed too.
    - Hyperoptimisation would be required to get an approach that would produce meaningful results. I imagine it'd be very unstable.
    - training would be:
        - use seed to generate network
        - apply network and learning paradigm to task
        - initial conditions based on seed would allow network to begin task, plasticity would allow it to adapt to task
        - eventually a seed would emerge that, despite being apparent chaos, would actually be a super advanced, mostly pretrained world-model that is also capable of plasticly dialling in
        - heavy pruning. We're born with more synapses than when we're grown - they disappear if they're irrelevant. Same approach here with the seeded model.
- plasticity. Jeepers.
    - network that acts as the reward centre that sits alongside the other reservoirs - may be a reservoir itself
    - converts state observations, possibly via other reasoning/rationalisation parts of the brain, into:
    - dopamine reward issuing. Observations are converted into essentially rewards that can be distributed among neurons
    - depending on timing and previous activations, neurons in the other networks can be issued with multipliers or enablers to increase synaptic strength
    - this reward centre model would be kinda the control system of the whole thing. If we get this right, the model will be aligned with our plans
    - reward centre model could/should be seed-based as with the rest? and we grade the result based on it's alingment.


I guess like, re:alignment and natural selection - is our platonic ideal model something we'll ever be able to constrain with just labelled data?

Whereas a natural selection approach - a serendipitous set of weights appears and fits everything we can throw at it, and we can bin it and fork off with another seed if we encounter a case where it performs not to our liking?

Or are they functionally equivalent?

### extra thought which is kinda handwavey
when a child is born, they have a brain that fits a general layout, but the specificity isn't dialled in yet. They prune and strengthen connections as they grow and learn

this could be seen as a pretrained + instruct tuned foundation model that is then finetuned as it goes.

I guess in current usage patterns, the pretrained/tuned model is used out of the box and finetuned models are a bit of a rarity

further, online trained models are basically unheard of, I think. I think because the reward model isn't present - we don't have RLHF to look after us on that data.

Whereas the above mentioned approach has the plasticity baked in. Obvs remains to be seen as this is entirely speculative.

### Attention and focus
I think attention mechanisms would be best applied in the readout layer

super confused and not sure where to place current approaches i.e. linear regression to readouts. Do those plasticise? are they fit at pretrain? What are they fit to? Are they part of the natural selection part?

## Genes/mutations
I guess a genetic code could be seen as a lossy compression of the initial conditions. Could we use genes and pass features to different generations?

Or might we as well just copy random selections of initial weights wholesale to children of successful instances?

or does the compression mechanism allow for higher-level guiding that makes convergence easier?

The code itself would need some sort of optimisation too, to be a representation of weights that allows for meaningful mutations, rather than just noise


# practicalities
lots of fun thinking here but I would like to start with some experimentation, because the whole line of thinking is so lofty and basically unverifiable unless I have heaps of gpus and a humanoid robot or something

- using a LSM (RC with spiking afaict) with clip embeddings or similar and seeing if we can get it to produce something meaningful from a video feed. Maybe counting instances of an object or something where it can act to add to the counter. Sounds simple but tbh would have to be quite far down the track
- generally, some async/ live processes with RC would be ideal
- using an RC for speech to text maybe?
- IMU data? mouse thing maybe
- building an RC from scratch with numpy and adding stuff on
    - distance matrix/buffer between neurons
    - LIF neurons - look into LSM literature on these
    - different types of neurons
    - attention layers for readout
