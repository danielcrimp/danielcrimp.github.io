---
layout: post
title: LowD
date: 2025-08-06
summary: Attempt N of trying to write about this idea
---

An idea I've found to be applicable across many domains is dimensionality of thinking.

This seems to have influence in engineering, design, government, corporations, technology, mental health, software and of course machine learning.

The idea is that any thinking system will need to develop an internal representation of things in it's environment.

Thinking systems will optimise their representations of the environment for maximum reward. If their rewards are single-dimensional, their internal model will discard any richness that does not contribute toward that goal. Almost as a rule, richer reward frameworks require richer appreciations of environment objects and often more complex, explorative arithmetic in action policies.