---
layout: post
title: LowD
date: 2025-08-06
summary: Attempt N of trying to write about this idea
---

An idea I've found to be applicable across many domains is dimensionality of thinking.

This seems to have influence in engineering, design, government, corporations, technology, mental health, software and of course machine learning.

Any thinking system will need to develop an internal representation of things in it's environment in order to predict what will happen next and act on it.

Thinking systems will optimise their representations of the environment for maximum reward. If their rewards are single-dimensional, their internal model will discard any richness that does not contribute toward that goal. Almost as a rule, richer reward frameworks require richer appreciations of environment objects and often more complex, explorative arithmetic in action policies.

Some systems are limited in capacity to handle many dimensions of representation. For example, bureaucratic organisations need to keep systems of record and communication simple so as to be able to process them at all.

In this way, bureaucracies necessarily have 